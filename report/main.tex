%\documentclass[10pt,twocolumn]{article}
\documentclass[10pt]{article}

\usepackage{times}
\usepackage{color}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{xspace}
\usepackage{setspace}
\usepackage{fullpage}
\usepackage{subcaption}
\usepackage{pbox}

\definecolor{CBlue}{rgb}{0.33,0.63,0.83}
%\newcommand{\david}[1]{}
%\newcommand{\shaddi}[1]{}
%\newcommand{\omer}[1]{}

\newcommand{\david}[1]{[\textcolor{red}{\textit{David: #1}}]}
\newcommand{\shaddi}[1]{[\textcolor{CBlue}{\textit{Shaddi: #1}}]}
\newcommand{\omer}[1]{[\textcolor{green}{\textit{Omer: #1}}]}

\title{Classifying Runtime Performance with SVM}

\author{David Eliahu \and Shaddi Hasan \and Omer Spillinger}

\begin{document}

\maketitle

\begin{abstract}
    We present a machine-learning based technique for the problem of \emph{algorithm selection}, specifically focusing on algorithms for dense matrix multiplication (DMM).
    Dense matrix multiplication is a core part of many high-performance computing and machine learning algorithms, but the performance of DMM algorithms can vary significantly based on their input and the performance characteristics of each particular machine.
    We model machine performance using support vector machines and show that only a small sample of possible inputs is sufficient to determine the best choice of algorithm over a wide range of possible inputs and even over different machines (by training a model per machine).
    We find that by using this classifier-based approach and choosing the best algorithm to use at runtime, we are able to achieve at least a 0.5\% and as much as a 28\% increase in performance over choosing a single algorithm a priori.
\end{abstract}

\input{introduction}
\input{related}
\input{dataset}
\input{classify}
\input{evaluation}
\input{future}
\input{conclusion}

\bibliographystyle{ieeetr}
\bibliography{main}

\end{document}
